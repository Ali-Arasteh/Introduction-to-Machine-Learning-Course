{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xT7wrj3KQdt"
      },
      "source": [
        "**Denoising by AEs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cngHJz2vJl5G"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "figsize = (15, 6)\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdyGzMH-LQcS"
      },
      "source": [
        "**Loading dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4bkzgoSKyl-"
      },
      "source": [
        "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=img_transform, download=True)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=img_transform, download=True)\n",
        "batch_size = 256\n",
        "n_iters = 10000\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "num_epochs = int(n_iters / (len(train_dataset) / batch_size))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7mf5NaDLmr4"
      },
      "source": [
        "Undercomplete\n",
        "\n",
        "**Autoencoder architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlgNKHadKyrR"
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.Tanh())\n",
        "        self.decoder = nn.Sequential(nn.Linear(128, 28 * 28), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89IdXlF-OKMk"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5b32qq_Kyve"
      },
      "source": [
        "learning_rate = 0.2\n",
        "model = autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "        img, _ = data\n",
        "        images = img.view(-1, 28 * 28).requires_grad_()\n",
        "        noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "        # ===================forward=====================\n",
        "        outputs = model.forward(noisy_images)\n",
        "        loss = criterion(outputs, images)\n",
        "        # ===================backward====================\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
        "    if epoch % 10 == 0:\n",
        "        losstotal = 0\n",
        "        for data in test_loader:\n",
        "            img, _ = data\n",
        "            images = img.view(-1, 28 * 28).requires_grad_()\n",
        "            noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "            output = model.forward(noisy_images)\n",
        "            losstotal += criterion(output, images)\n",
        "    losstotal = losstotal / len(test_loader)\n",
        "print('Loss Test: {}'.format(losstotal))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/42], loss: 0.2235\n",
            "epoch [2/42], loss: 0.1704\n",
            "epoch [3/42], loss: 0.1594\n",
            "epoch [4/42], loss: 0.1412\n",
            "epoch [5/42], loss: 0.1380\n",
            "epoch [6/42], loss: 0.1220\n",
            "epoch [7/42], loss: 0.1199\n",
            "epoch [8/42], loss: 0.1211\n",
            "epoch [9/42], loss: 0.1001\n",
            "epoch [10/42], loss: 0.1059\n",
            "epoch [11/42], loss: 0.1083\n",
            "epoch [12/42], loss: 0.1106\n",
            "epoch [13/42], loss: 0.1040\n",
            "epoch [14/42], loss: 0.0914\n",
            "epoch [15/42], loss: 0.0961\n",
            "epoch [16/42], loss: 0.0984\n",
            "epoch [17/42], loss: 0.0885\n",
            "epoch [18/42], loss: 0.0883\n",
            "epoch [19/42], loss: 0.0890\n",
            "epoch [20/42], loss: 0.0873\n",
            "epoch [21/42], loss: 0.0896\n",
            "epoch [22/42], loss: 0.0831\n",
            "epoch [23/42], loss: 0.0849\n",
            "epoch [24/42], loss: 0.0806\n",
            "epoch [25/42], loss: 0.0847\n",
            "epoch [26/42], loss: 0.0782\n",
            "epoch [27/42], loss: 0.0832\n",
            "epoch [28/42], loss: 0.0788\n",
            "epoch [29/42], loss: 0.0728\n",
            "epoch [30/42], loss: 0.0756\n",
            "epoch [31/42], loss: 0.0706\n",
            "epoch [32/42], loss: 0.0707\n",
            "epoch [33/42], loss: 0.0681\n",
            "epoch [34/42], loss: 0.0681\n",
            "epoch [35/42], loss: 0.0745\n",
            "epoch [36/42], loss: 0.0729\n",
            "epoch [37/42], loss: 0.0663\n",
            "epoch [38/42], loss: 0.0707\n",
            "epoch [39/42], loss: 0.0645\n",
            "epoch [40/42], loss: 0.0698\n",
            "epoch [41/42], loss: 0.0677\n",
            "epoch [42/42], loss: 0.0632\n",
            "Loss Test: 0.0016925781965255737\n"
          ]
        }
      ]
    },
    {
      "source": [
        "Overcomplete\n",
        "\n",
        "**Autoencoder architecture**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 1000), nn.Tanh())\n",
        "        self.decoder = nn.Sequential(nn.Linear(1000, 28 * 28), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "source": [
        "**Evaluation**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/42], loss: 0.1411\n",
            "epoch [2/42], loss: 0.1012\n",
            "epoch [3/42], loss: 0.0934\n",
            "epoch [4/42], loss: 0.0897\n",
            "epoch [5/42], loss: 0.0817\n",
            "epoch [6/42], loss: 0.0728\n",
            "epoch [7/42], loss: 0.0797\n",
            "epoch [8/42], loss: 0.0743\n",
            "epoch [9/42], loss: 0.0717\n",
            "epoch [10/42], loss: 0.0706\n",
            "epoch [11/42], loss: 0.0614\n",
            "epoch [12/42], loss: 0.0653\n",
            "epoch [13/42], loss: 0.0591\n",
            "epoch [14/42], loss: 0.0595\n",
            "epoch [15/42], loss: 0.0523\n",
            "epoch [16/42], loss: 0.0546\n",
            "epoch [17/42], loss: 0.0559\n",
            "epoch [18/42], loss: 0.0484\n",
            "epoch [19/42], loss: 0.0523\n",
            "epoch [20/42], loss: 0.0518\n",
            "epoch [21/42], loss: 0.0464\n",
            "epoch [22/42], loss: 0.0461\n",
            "epoch [23/42], loss: 0.0520\n",
            "epoch [24/42], loss: 0.0470\n",
            "epoch [25/42], loss: 0.0435\n",
            "epoch [26/42], loss: 0.0458\n",
            "epoch [27/42], loss: 0.0402\n",
            "epoch [28/42], loss: 0.0450\n",
            "epoch [29/42], loss: 0.0392\n",
            "epoch [30/42], loss: 0.0435\n",
            "epoch [31/42], loss: 0.0351\n",
            "epoch [32/42], loss: 0.0420\n",
            "epoch [33/42], loss: 0.0463\n",
            "epoch [34/42], loss: 0.0393\n",
            "epoch [35/42], loss: 0.0396\n",
            "epoch [36/42], loss: 0.0413\n",
            "epoch [37/42], loss: 0.0367\n",
            "epoch [38/42], loss: 0.0387\n",
            "epoch [39/42], loss: 0.0411\n",
            "epoch [40/42], loss: 0.0365\n",
            "epoch [41/42], loss: 0.0375\n",
            "epoch [42/42], loss: 0.0359\n",
            "Loss Test: 0.0009169093100354075\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.2\n",
        "model = autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "        img, _ = data\n",
        "        images = img.view(-1, 28 * 28).requires_grad_()\n",
        "        noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "        # ===================forward=====================\n",
        "        outputs = model.forward(noisy_images)\n",
        "        loss = criterion(outputs, images)\n",
        "        # ===================backward====================\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
        "    if epoch % 10 == 0:\n",
        "        losstotal = 0\n",
        "        for data in test_loader:\n",
        "            img, _ = data\n",
        "            images = img.view(-1, 28 * 28).requires_grad_()\n",
        "            noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "            output = model.forward(noisy_images)\n",
        "            losstotal += criterion(output, images)\n",
        "    losstotal = losstotal / len(test_loader)\n",
        "print('Loss Test: {}'.format(losstotal))"
      ]
    },
    {
      "source": [
        "The objective of undercomplete autoencoder is to capture the most important features present in the data. Undercomplete autoencoders have a smaller dimension for hidden layer compared to the input layer. This helps to obtain important features from the data. Undercomplete autoencoders do not need any regularization as they maximize the probability of data rather than copying the input to the output.\n",
        "\n",
        "In contrast, if the hidden layers are larger than (overcomplete autoencoders), or equal to, the input layer, or the hidden units are given enough capacity, an autoencoder can potentially learn the identity function and become useless. However, experimental results have shown that autoencoders might still learn useful features in these cases. In the ideal setting, one should be able to tailor the code dimension and the model capacity on the basis of the complexity of the data distribution to be modeled. One way to do so, is to exploit the model variants known as Regularized Autoencoders.\n",
        "\n",
        "As a result, overcomplete autoencoders normally have better performance rather than undercomplete autoencoders."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "**Evaluation**\n",
        "\n",
        "With L1 regularization"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/42], loss: 0.1705\n",
            "epoch [2/42], loss: 0.1500\n",
            "epoch [3/42], loss: 0.1344\n",
            "epoch [4/42], loss: 0.1210\n",
            "epoch [5/42], loss: 0.1206\n",
            "epoch [6/42], loss: 0.1124\n",
            "epoch [7/42], loss: 0.1059\n",
            "epoch [8/42], loss: 0.1034\n",
            "epoch [9/42], loss: 0.1006\n",
            "epoch [10/42], loss: 0.0969\n",
            "epoch [11/42], loss: 0.0980\n",
            "epoch [12/42], loss: 0.0913\n",
            "epoch [13/42], loss: 0.0874\n",
            "epoch [14/42], loss: 0.0931\n",
            "epoch [15/42], loss: 0.0860\n",
            "epoch [16/42], loss: 0.0797\n",
            "epoch [17/42], loss: 0.0754\n",
            "epoch [18/42], loss: 0.0810\n",
            "epoch [19/42], loss: 0.0775\n",
            "epoch [20/42], loss: 0.0863\n",
            "epoch [21/42], loss: 0.0821\n",
            "epoch [22/42], loss: 0.0751\n",
            "epoch [23/42], loss: 0.0754\n",
            "epoch [24/42], loss: 0.0752\n",
            "epoch [25/42], loss: 0.0703\n",
            "epoch [26/42], loss: 0.0731\n",
            "epoch [27/42], loss: 0.0693\n",
            "epoch [28/42], loss: 0.0688\n",
            "epoch [29/42], loss: 0.0714\n",
            "epoch [30/42], loss: 0.0676\n",
            "epoch [31/42], loss: 0.0694\n",
            "epoch [32/42], loss: 0.0625\n",
            "epoch [33/42], loss: 0.0632\n",
            "epoch [34/42], loss: 0.0658\n",
            "epoch [35/42], loss: 0.0655\n",
            "epoch [36/42], loss: 0.0664\n",
            "epoch [37/42], loss: 0.0650\n",
            "epoch [38/42], loss: 0.0618\n",
            "epoch [39/42], loss: 0.0627\n",
            "epoch [40/42], loss: 0.0610\n",
            "epoch [41/42], loss: 0.0616\n",
            "epoch [42/42], loss: 0.0603\n",
            "Loss Test: 0.0008941208943724632\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.2\n",
        "C = 0.1\n",
        "model = autoencoder()\n",
        "criterion1 = nn.MSELoss()\n",
        "criterion2 = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "        img, _ = data\n",
        "        images = img.view(-1, 28 * 28).requires_grad_()\n",
        "        noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "        # ===================forward=====================\n",
        "        outputs = model.forward(noisy_images)\n",
        "        h = model.encoder(noisy_images)\n",
        "        loss = criterion1(outputs, images) + C * criterion2(h, torch.zeros(h.shape))\n",
        "        # ===================backward====================\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
        "    if epoch % 10 == 0:\n",
        "        losstotal = 0\n",
        "        for data in test_loader:\n",
        "            img, _ = data\n",
        "            images = img.view(-1, 28 * 28).requires_grad_()\n",
        "            noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "            output = model.forward(noisy_images)\n",
        "            losstotal += criterion(output, images)\n",
        "    losstotal = losstotal / len(test_loader)\n",
        "print('Loss Test: {}'.format(losstotal))"
      ]
    },
    {
      "source": [
        "**Evaluation**\n",
        "\n",
        "With L2 regularization"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/42], loss: 0.1591\n",
            "epoch [2/42], loss: 0.1324\n",
            "epoch [3/42], loss: 0.1226\n",
            "epoch [4/42], loss: 0.1098\n",
            "epoch [5/42], loss: 0.0959\n",
            "epoch [6/42], loss: 0.0975\n",
            "epoch [7/42], loss: 0.0948\n",
            "epoch [8/42], loss: 0.0883\n",
            "epoch [9/42], loss: 0.0797\n",
            "epoch [10/42], loss: 0.0818\n",
            "epoch [11/42], loss: 0.0796\n",
            "epoch [12/42], loss: 0.0705\n",
            "epoch [13/42], loss: 0.0734\n",
            "epoch [14/42], loss: 0.0700\n",
            "epoch [15/42], loss: 0.0752\n",
            "epoch [16/42], loss: 0.0687\n",
            "epoch [17/42], loss: 0.0725\n",
            "epoch [18/42], loss: 0.0665\n",
            "epoch [19/42], loss: 0.0615\n",
            "epoch [20/42], loss: 0.0605\n",
            "epoch [21/42], loss: 0.0596\n",
            "epoch [22/42], loss: 0.0614\n",
            "epoch [23/42], loss: 0.0545\n",
            "epoch [24/42], loss: 0.0548\n",
            "epoch [25/42], loss: 0.0576\n",
            "epoch [26/42], loss: 0.0539\n",
            "epoch [27/42], loss: 0.0545\n",
            "epoch [28/42], loss: 0.0548\n",
            "epoch [29/42], loss: 0.0524\n",
            "epoch [30/42], loss: 0.0537\n",
            "epoch [31/42], loss: 0.0498\n",
            "epoch [32/42], loss: 0.0447\n",
            "epoch [33/42], loss: 0.0543\n",
            "epoch [34/42], loss: 0.0498\n",
            "epoch [35/42], loss: 0.0499\n",
            "epoch [36/42], loss: 0.0492\n",
            "epoch [37/42], loss: 0.0479\n",
            "epoch [38/42], loss: 0.0446\n",
            "epoch [39/42], loss: 0.0477\n",
            "epoch [40/42], loss: 0.0460\n",
            "epoch [41/42], loss: 0.0440\n",
            "epoch [42/42], loss: 0.0456\n",
            "Loss Test: 0.0008824920514598489\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.2\n",
        "C = 0.1\n",
        "model = autoencoder()\n",
        "criterion1 = nn.MSELoss()\n",
        "criterion2 = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "        img, _ = data\n",
        "        images = img.view(-1, 28 * 28).requires_grad_()\n",
        "        noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "        # ===================forward=====================\n",
        "        outputs = model.forward(noisy_images)\n",
        "        h = model.encoder(noisy_images)\n",
        "        loss = criterion1(outputs, images) + C * criterion2(h, torch.zeros(h.shape))\n",
        "        # ===================backward====================\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
        "    if epoch % 10 == 0:\n",
        "        losstotal = 0\n",
        "        for data in test_loader:\n",
        "            img, _ = data\n",
        "            images = img.view(-1, 28 * 28).requires_grad_()\n",
        "            noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "            output = model.forward(noisy_images)\n",
        "            losstotal += criterion(output, images)\n",
        "    losstotal = losstotal / len(test_loader)\n",
        "print('Loss Test: {}'.format(losstotal))"
      ]
    },
    {
      "source": [
        "With dropout regularization\n",
        "\n",
        "**Autoencoder architecture**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self, dp):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 1000), nn.Tanh())\n",
        "        self.decoder = nn.Sequential(nn.Dropout(p=dp), nn.Linear(1000, 28 * 28), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "source": [
        "**Evaluation**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1/42], loss: 0.1603\n",
            "epoch [2/42], loss: 0.1261\n",
            "epoch [3/42], loss: 0.1104\n",
            "epoch [4/42], loss: 0.1047\n",
            "epoch [5/42], loss: 0.0902\n",
            "epoch [6/42], loss: 0.0923\n",
            "epoch [7/42], loss: 0.0910\n",
            "epoch [8/42], loss: 0.0793\n",
            "epoch [9/42], loss: 0.0844\n",
            "epoch [10/42], loss: 0.0774\n",
            "epoch [11/42], loss: 0.0748\n",
            "epoch [12/42], loss: 0.0795\n",
            "epoch [13/42], loss: 0.0688\n",
            "epoch [14/42], loss: 0.0686\n",
            "epoch [15/42], loss: 0.0631\n",
            "epoch [16/42], loss: 0.0711\n",
            "epoch [17/42], loss: 0.0709\n",
            "epoch [18/42], loss: 0.0648\n",
            "epoch [19/42], loss: 0.0609\n",
            "epoch [20/42], loss: 0.0596\n",
            "epoch [21/42], loss: 0.0624\n",
            "epoch [22/42], loss: 0.0570\n",
            "epoch [23/42], loss: 0.0578\n",
            "epoch [24/42], loss: 0.0568\n",
            "epoch [25/42], loss: 0.0508\n",
            "epoch [26/42], loss: 0.0556\n",
            "epoch [27/42], loss: 0.0555\n",
            "epoch [28/42], loss: 0.0560\n",
            "epoch [29/42], loss: 0.0528\n",
            "epoch [30/42], loss: 0.0482\n",
            "epoch [31/42], loss: 0.0537\n",
            "epoch [32/42], loss: 0.0475\n",
            "epoch [33/42], loss: 0.0508\n",
            "epoch [34/42], loss: 0.0486\n",
            "epoch [35/42], loss: 0.0470\n",
            "epoch [36/42], loss: 0.0489\n",
            "epoch [37/42], loss: 0.0449\n",
            "epoch [38/42], loss: 0.0464\n",
            "epoch [39/42], loss: 0.0487\n",
            "epoch [40/42], loss: 0.0432\n",
            "epoch [41/42], loss: 0.0486\n",
            "epoch [42/42], loss: 0.0449\n",
            "Loss Test: 0.001183653250336647\n"
          ]
        }
      ],
      "source": [
        "dp = 0.4\n",
        "learning_rate = 0.2\n",
        "model = autoencoder(dp)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "        img, _ = data\n",
        "        images = img.view(-1, 28 * 28).requires_grad_()\n",
        "        noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "        # ===================forward=====================\n",
        "        outputs = model.forward(noisy_images)\n",
        "        loss = criterion(outputs, images)\n",
        "        # ===================backward====================\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
        "    if epoch % 10 == 0:\n",
        "        losstotal = 0\n",
        "        for data in test_loader:\n",
        "            img, _ = data\n",
        "            images = img.view(-1, 28 * 28).requires_grad_()\n",
        "            noisy_images = images + 0.1 * torch.randn(images.shape)\n",
        "            output = model.forward(noisy_images)\n",
        "            losstotal += criterion(output, images)\n",
        "    losstotal = losstotal / len(test_loader)\n",
        "print('Loss Test: {}'.format(losstotal))"
      ]
    },
    {
      "source": [
        "Various techniques exist to prevent autoencoders from learning the identity function and to improve their ability to capture important information and learn richer representations.\n",
        "\n",
        "Recently, it has been observed that when representations are learnt in a way that encourages sparsity, improved performance is obtained on classification tasks. Sparse autoencoder may include more (rather than fewer) hidden units than inputs, but only a small number of the hidden units are allowed to be active at once. This sparsity constraint forces the model to respond to the unique statistical features of the input data used for training. Specifically, a sparse autoencoder is an autoencoder whose training criterion involves a sparsity penalty $\\Omega(h)$ on the code layer $h$.\n",
        "\n",
        "One of the methods to achieve sparsity in the activation of the hidden unit, is by applying L1 or L2 regularization terms on the activation, scaled by a certain parameter $\\lambda$. Dropout can also be used in this regard.\n",
        "\n",
        "Based on the result, L1 and L2 regularization are better than dropout method and can improve overcomplete autoencoder model on test data."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiS56nh9NUen"
      },
      "source": [
        "NOTE: add your explanation after each part "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf-OVH75QAac"
      },
      "source": [
        "images = train_dataset.data / 128 - 1\n",
        "perm = torch.randperm(len(images))\n",
        "original_img = images[perm][0].view(-1, 28 * 28).requires_grad_()\n",
        "noisy_img = original_img + 0.1 * torch.randn(original_img.shape)\n",
        "output_img = model.forward(noisy_img)\n",
        "original_img = original_img.reshape(28, 28)\n",
        "noisy_img = noisy_img.reshape(28, 28)\n",
        "output_img = output_img.reshape(28, 28)\n",
        "fig = plt.figure(figsize=figsize)\n",
        "ax = fig.add_subplot(131, xticks=[], yticks=[])\n",
        "ax.imshow(original_img.detach())\n",
        "ax.set_title('Original Image')\n",
        "ax = fig.add_subplot(132, xticks=[], yticks=[])\n",
        "ax.imshow(noisy_img.detach())\n",
        "ax.set_title('Noisy Image')\n",
        "ax = fig.add_subplot(133, xticks=[], yticks=[])\n",
        "ax.imshow(output_img.detach())\n",
        "ax.set_title('Output Image')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1080x432 with 3 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"312.071391pt\" version=\"1.1\" viewBox=\"0 0 954 312.071391\" width=\"954pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 312.071391 \r\nL 954 312.071391 \r\nL 954 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#f0f0f0;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 7.2 304.871391 \r\nL 283.552941 304.871391 \r\nL 283.552941 28.51845 \r\nL 7.2 28.51845 \r\nz\r\n\" style=\"fill:#f0f0f0;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p80ab465e04)\">\r\n    <image height=\"277\" id=\"imageaf9eafbe29\" transform=\"scale(1 -1)translate(0 -277)\" width=\"277\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAARUAAAEVCAYAAADO7nHiAAAABHNCSVQICAgIfAhkiAAACgFJREFUeJzt3duP3HUdxvGZ3Z3dnW2XbekJeqCkChaUpqmx4aAXohxuCBqBxKiJgcRbL7hUozdyozFGoyT+CXKlCZ4wREBQiEagmkKRtrQFeqRbtu0eZmfGP8Am82T306XK63X95Ldblrznd/HNd5qfbz7Qb7A0Q8PZrtct/bFv/fKWaNfvN6Nd87XVAzfbv/tC9KzU4e/fFu364X/i1W9luw2P/yUbsmRDH/QvAPx/ERWglKgApUQFKCUqQClRAUqJClBKVIBSogKUajpRu3TNsbFo15+fj3YjW7dEu+88++tot3lkNtpNBSeDH9qanYBNfePAwWi3e+ydaDc5lJ0e/tq2O6IdS+dNBSglKkApUQFKiQpQSlSAUqIClBIVoJSoAKVEBSg18kH/Av/L+p3F0ucd+vr2aHehPxrtXp6fjHbf23/fwM2GxuvRs1Jz/Va0e7s7+P7cRqPR+N17u5bz61DImwpQSlSAUqIClBIVoJSoAKVEBSglKkApUQFKiQpQyonaZWiG96L2e9nz5jZ2o926oYvRbqbXjnbd3sp/tqwbPh/tDi+sj3Z3TB6Idi/e+ZVoN/L036Md/82bClBKVIBSogKUEhWglKgApUQFKCUqQClRAUqJClDKidpl6C/W3lG7attMtOs2spO8k0Oz0W7tRLaLNLPf7d6J+Wj32Onro91oMzuNPLcu+18+uxmXS/GmApQSFaCUqAClRAUoJSpAKVEBSokKUEpUgFIOv11BvnXzb6PdawvXRrudo+9GuxPPbx64ua5xOHpWo9/PdqGrR7JrJ8eHOtGufSrbsXTeVIBSogKUEhWglKgApUQFKCUqQClRAUqJClBKVIBSTtReQaa7E9Gu08/+bHOtbLfqWO0p2MS5XnaF5Z724Wh3tLMu2jW7K/9v/bDxpgKUEhWglKgApUQFKCUqQClRAUqJClBKVIBSogKUcqJ2BSzc+6lot6f982j35Pu7o910Lzuhu/GF0wM32def5053syce7WyKdsPNXvZzd7Wj3cbnohmX4E0FKCUqQClRAUqJClBKVIBSogKUEhWglKgApUQFKOVE7Qo4fH8z2vX6WeM/3j4W7e5tX4x2P9n/RrSrNNNrlT5vvNmJdu6ovfy8qQClRAUoJSpAKVEBSokKUEpUgFKiApQSFaCUqAClnKhdAWPrZqPdmd6qaJeeHr17/xei3UjjSLSrtHlkMdpN985Hu/d748v5dSjkTQUoJSpAKVEBSokKUEpUgFKiApQSFaCUqAClRAUo5UTtCrj/hn3RrtPP/hzT3Ylod/DIxmh34wdwovaJmZ3RbkvrbLS7u/1etPv2RHZfMEvnTQUoJSpAKVEBSokKUEpUgFKiApQSFaCUqAClRAUo5UTtCnh0/fPR7rnZa6PdLWPHot1Vr45Gu0rNsbFod83IuWh3dGFd9oPDE7WbXrqYPY8l86YClBIVoJSoAKVEBSglKkApUQFKiQpQSlSAUqIClHKidgVMDWUnW492ro52reZitNv+xYPRbv7H0SwytOO6aLet9edo9+/5TdHudG8h2h2/Nbvfd3P263EJ3lSAUqIClBIVoJSoAKVEBSglKkApUQFKiQpQSlSAUk7ULsPIls3RbqzZinbnu+PRrhd+FswuZj+38pPl1G3ro93NrW60e6bZi3bHu9nduHMb+tGOpfOmApQSFaCUqAClRAUoJSpAKVEBSokKUEpUgFKiApRyonYZupvXlT6v0x+OdtPd7J7Vz244EO2eabSjXeLMnuwE7CsL2b29b8+vjXZvtK6JdhMfm452LJ03FaCUqAClRAUoJSpAKVEBSokKUEpUgFKiApRy+G0Z+sPN0ue1mtkVi91+9llwz+S+aPdMY2+0S9y+5/VoNx5+yfzUyGy0mwmv4pxqz0U7ls6bClBKVIBSogKUEhWglKgApUQFKCUqQClRAUqJClDKidplOPOJVaXPO7kwGe2Oz09Fu69edTTaDd+wY+Cm+8bB6Fk/2vZktDu8mF0nmbp94s1o94N/3RftPto4tJxf50PNmwpQSlSAUqIClBIVoJSoAKVEBSglKkApUQFKiQpQyonaZZg6tBDtTncvRLuxoeze1qOz2ZeWH+x0ot1bDw7+cvOtj2UnajcOZ6eMn7qYfbn9+cWxaLdvfku0Gz/lc/Ry818YKCUqQClRAUqJClBKVIBSogKUEhWglKgApUQFKOVE7TK0nt0X7dYOtaPd7lVHot0N7RPR7pXwlOldX3pp4ObpvTdFz2o0Xo5Wh+Y3RLvpzkS0m+u1ot3EiX60Y+m8qQClRAUoJSpAKVEBSokKUEpUgFKiApQSFaCUqAClnKhdhn4nu6M2Nd3NTo9ODs1Gu4X+cLR7cO3gE7WPbXohetYvzl0f7VrNbrRb07oY7b48mZ1G/ll25S3L4E0FKCUqQClRAUqJClBKVIBSogKUEhWglKgApUQFKOVE7Qp4czE7AbtqaD7anVicinZTw9nP7QafLce6nehZt7YPRrt94f25F3uj0e5ENzvdvObN7N/B0nlTAUqJClBKVIBSogKUEhWglKgApUQFKCUqQClRAUo5UbsCTnXb0W6u14p2R+eujnYTE8ej3ZPndg/cfGT8ZPSsG0ezn3mhl10W+4/pbdHukbUvRruRGSdqLzdvKkApUQFKiQpQSlSAUqIClBIVoJSoAKVEBSglKkApJ2pXwKnuVdFu59i70e6HL98V7a66eS7a7Zo4OnDzp+md0bNOtrN/603j70S7HatPR7u/zmV33g51utGuH624FG8qQClRAUqJClBKVIBSogKUEhWglKgApUQFKCUqQCknalfAT9+6M9p9c/sfS3/up1cfiHaHF9YP3Hxm6vXoWRfDu2d/896uaNcezu6U3Tl6ItqdvWky2q35WzTjErypAKVEBSglKkApUQFKiQpQSlSAUqIClBIVoJTDbyvg5O+3RrvpRyai3dCR7Avfh/b2ot1cf/AXw891sy+Pf2Um+0L1YxfWRLtda96Odquai9Fu/VMHo132NC7FmwpQSlSAUqIClBIVoJSoAKVEBSglKkApUQFKiQpQyonaFbD1D2ejXefh7M+x5ZPZl5s/cWZvtNvePjNwc+N49uXxh1uDr6ZsNBqNmdHs2smNozPR7qFXH452649nV2yydN5UgFKiApQSFaCUqAClRAUoJSpAKVEBSokKUEpUgFJO1K6A3iv7o90Dk4ei3fU7TkW7z7W70a7TH7w70FmInnXPpuPR7p8L2Yna1+Y3R7vZ+dFox+XnTQUoJSpAKVEBSokKUEpUgFKiApQSFaCUqAClRAUo5UTtFeS2xx+Ndour+9Fu9Fwz2q0+1hu4mZ/KPn8WJ6JZozWT/RvO7u1Eu22/8vl4pfCXAEqJClBKVIBSogKUEhWglKgApUQFKCUqQClRAUr9B5xAqxld/zrBAAAAAElFTkSuQmCC\" y=\"-27.871391\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\"/>\r\n   <g id=\"matplotlib.axis_2\"/>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 7.2 304.871391 \r\nL 7.2 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 283.552941 304.871391 \r\nL 283.552941 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 7.2 304.871391 \r\nL 283.552941 304.871391 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 7.2 28.51845 \r\nL 283.552941 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"text_1\">\r\n    <!-- Original Image -->\r\n    <defs>\r\n     <path d=\"M 39.40625 66.21875 \r\nQ 28.65625 66.21875 22.328125 58.203125 \r\nQ 16.015625 50.203125 16.015625 36.375 \r\nQ 16.015625 22.609375 22.328125 14.59375 \r\nQ 28.65625 6.59375 39.40625 6.59375 \r\nQ 50.140625 6.59375 56.421875 14.59375 \r\nQ 62.703125 22.609375 62.703125 36.375 \r\nQ 62.703125 50.203125 56.421875 58.203125 \r\nQ 50.140625 66.21875 39.40625 66.21875 \r\nz\r\nM 39.40625 74.21875 \r\nQ 54.734375 74.21875 63.90625 63.9375 \r\nQ 73.09375 53.65625 73.09375 36.375 \r\nQ 73.09375 19.140625 63.90625 8.859375 \r\nQ 54.734375 -1.421875 39.40625 -1.421875 \r\nQ 24.03125 -1.421875 14.8125 8.828125 \r\nQ 5.609375 19.09375 5.609375 36.375 \r\nQ 5.609375 53.65625 14.8125 63.9375 \r\nQ 24.03125 74.21875 39.40625 74.21875 \r\nz\r\n\" id=\"DejaVuSans-79\"/>\r\n     <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n     <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n     <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n     <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n     <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n     <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n     <path id=\"DejaVuSans-32\"/>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-73\"/>\r\n     <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n     <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n    </defs>\r\n    <g transform=\"translate(71.157746 22.51845)scale(0.2016 -0.2016)\">\r\n     <use xlink:href=\"#DejaVuSans-79\"/>\r\n     <use x=\"78.710938\" xlink:href=\"#DejaVuSans-114\"/>\r\n     <use x=\"119.824219\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"147.607422\" xlink:href=\"#DejaVuSans-103\"/>\r\n     <use x=\"211.083984\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"238.867188\" xlink:href=\"#DejaVuSans-110\"/>\r\n     <use x=\"302.246094\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"363.525391\" xlink:href=\"#DejaVuSans-108\"/>\r\n     <use x=\"391.308594\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"423.095703\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"452.587891\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"550\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"611.279297\" xlink:href=\"#DejaVuSans-103\"/>\r\n     <use x=\"674.755859\" xlink:href=\"#DejaVuSans-101\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_7\">\r\n    <path d=\"M 338.823529 304.871391 \r\nL 615.176471 304.871391 \r\nL 615.176471 28.51845 \r\nL 338.823529 28.51845 \r\nz\r\n\" style=\"fill:#f0f0f0;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p9483f64152)\">\r\n    <image height=\"277\" id=\"imagee6307f7948\" transform=\"scale(1 -1)translate(0 -277)\" width=\"277\" x=\"338.823529\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAARUAAAEVCAYAAADO7nHiAAAABHNCSVQICAgIfAhkiAAAEdFJREFUeJzt3UuMnfddxvH/+573XOZ+scceezK+jGM7NzdN0lCloVBASgoCVWy6ASGxY0dBAiT2CMEKqWxALNgQIVhRFWoZtVLoBZI2SQMNjYNdx/exPZ7bOTNz5lzelwUrVu9X4idlwfezfnRmzpzjx2fx6HeyL5793SoB5dwUiaWUZSy210e58UL9z83GJXqs/M4jlEuLcyz38DGKZTPTKFe1Wyj34R/OolzRHqFcebv+b3zxz26ixxqsHUe5W693UI4q9tj7bvXyDsqNp5rs526z93E2BK9F0UCPVTXgv7FD9vpTVbNAuTz0p0r6f89SkRTKUpEUylKRFMpSkRTKUpEUylKRFMpSkRTKUpEUqhiuLKJgPhijXGNjF+UGKwvs8Q6G9ZmHbCU5uLCCcnSxWEy1UY6ujMsWW1R+9dU3UG4qG6Bc86fql5d/9FdfZo+10UO5X3j9xyj35cW3Ue7uiL2f3njjcyhXtdnjjRYmUK5452p96Pxp9Fj57j7KVQ32maGaYuvmquWiVtInwFKRFMpSkRTKUpEUylKRFMpSkRTKUpEUylKRFMpSkRSqaN7fZslB/bI1pZSGp5dQrrnOVrCpu1cbqebZzdbWbXZTdngSrn3vb6LceIP93HtfeQnl9kq25P3BwRrKXbn/VG1mnr7+J+ZR7mSbve++t3ce5R4OZ1CunGG3lhvX76NcMcUWtdXKcm2mzOH/8SW7yZzgTdls/zA05ycVSaEsFUmhLBVJoSwVSaEsFUmhLBVJoSwVSaEsFUmhLBVJoYrywSMUzE6dRLnmHbYeTXA9ODhf/3Obj9hd1DRmS8T8sP5ma0opVZPstme+dgrlBvMVyr3UvotyP9xjN097/fqF7lyT3bvNh+xv/NzEHZS7O2Tr5sWCvQf+5adfRrljP2Br1Kpg7+O8X/+eqtrsRvHg1FGUowtyekM5jdidaj+pSAplqUgKZalICmWpSAplqUgKZalICmWpSAplqUgKZalIClVkHXbvNOsdoNx4mS0gx3A92Diov42aHbK1ZxqyO6uNTbbOHJxaRLniMfvbrb7MlrLfhrdnz3UeotyJ2dXazOFq/Y3VlFLqfPQA5VYLdt93fTiHctS4A9ej9PEm2PK2uFn/WpSnj/1ff53/rc9uyo5OsZ+bD1zUSvoEWCqSQlkqkkJZKpJCWSqSQlkqkkJZKpJCWSqSQhWji/XDp5RSauzD4dj6FspVJ9hIDj1Wq4ly5RIbUuW32ICrud5FuTRmo6E/f/JvUe7qkI2VvttlX25+7d3698AF+GX0qWInMbdL9sXmO+NJlBtWbEzZ2WS/37gDR21dNryswBCtWGdfWl8d9FEuTbK/ceMn91Bu/OQKyvlJRVIoS0VSKEtFUihLRVIoS0VSKEtFUihLRVIoS0VSKEtFUqiieWsDBcfH59kjNtkSMYNf5J1du1WbqUr2WIdrz6BcKzuOcsXDHZSr2i2U+0bvOZTbHE2h3Bdmf4xy/7jzSn0Ifrl9Ktiy9VJrF+WGVf3rn1JKl3cuoVwF/xtt3WT/Lsojs+wBTyzVZ/rwLGoJV8GL0yiXN+CXzH9wg+VQSpIgS0VSKEtFUihLRVIoS0VSKEtFUihLRVIoS0VSKEtFUqii6rC1Z37nEcqNV9n91Kw/QrnqwqnaTL7LvgC92WV3dkfT7G/SP86+tPxwjnX3b879COXe6F5EOeqJb+3XZsZz7N5pOTGDcn14y/bjwVGUO9VmN3Qvs++2T0e/zt5TacRWqyPy91tg93hHa0dQrvUY3rKFN57zJfZz/aQiKZSlIimUpSIplKUiKZSlIimUpSIplKUiKZSlIimUpSIpVDFcnkPBZoPdHm3cZ8vGwVm4vB3XLy/H8Dm0Pmar4PwofLyNMcrd+m22urw6bKNcJ2PL4Ncm9lDuq/v1jzeeZSvj1i32+n+/fxLlJvNDlBtW7DZyaydDufEa+/2Ku49RrpysX6MW99nN42bOPgsMVhZQrrHJ7gWXG+y19ZOKpFCWiqRQloqkUJaKpFCWiqRQloqkUJaKpFCWiqRQloqkUEXjgK0zswHLpTZcXt7cQLmqXX8/Mxuye7cJ3kUtO2ydWeywv0l7hq1Cf9ivv8ebUkqdnP3cL330KyiX79f/fnm3/o5tSimNj7AbtWea7PX/cHAC5fpwUZuxEXRq9NhrVh6ZRbniXv0atZpid4BHR9lCm77fx0tsQZ6OzaOYn1QkhbJUJIWyVCSFslQkhbJUJIWyVCSFslQkhbJUJIWyVCSFYjPElFLVY4vK8vRxlBvNwOXtw/o7qxVc8abDAYo19lkuPWCr0J89c8AebsiWjYcle9k+vLWMcufn6he6jR32HPJtdhf3+nAJ5T7qs+fwB0feQ7m/33oN5RJckGdjdrs5Ner//x4usaVs6/o6ypW7XZRLZ1dRLIMLXT+pSAplqUgKZalICmWpSAplqUgKZalICmWpSAplqUgKZalIClUk+A3y47Ns2ViB5eD/BFks265fBdLbnuXMJMo1tnsoN7zAloivzH4D5d7urqHcp6dvodzkf3ZQLqX69WjVZivefJetkbtj9pqNK/Z+mszZqnpqHd5abrLn219hN2qbPbBa3mO/WzVkuXxxAeUG8+x9Uuz22c9FKUmCLBVJoSwVSaEsFUmhLBVJoSwVSaEsFUmhLBVJoSwVSaGKssl6pdhiN2qrJrvZWVx7jHL9S6dqM+37u+ixygm4Cu2x50Bv2a61HqLcd8vzKHe9fwzlWq+yv3HjL8DN05JNoMfn2cr4cxM/QTl6t/fOiK2g732+iXKnLk+hXHud3eTNwM3b7OAQPVa1OI9y41m2Wm5uwvvTbfa385OKpFCWiqRQloqkUJaKpFCWiqRQloqkUJaKpFCWiqRQloqkUEWxw+5OZn22Hi2n2c3ObJEtJTsf169Cqy5bNRZZhnLDZfa75cMxys1mbCmZZyXKLRbs+XZ7bFG5dKF+tZwP2HO9/3n2t5vJ2XPtjdso9+bBaZQbzrBlcOveNnu84+z5Nt77uDaTHT2CHivbZ/9myyPTKNfYYov0RoMtzf2kIimUpSIplKUiKZSlIimUpSIplKUiKZSlIimUpSIplKUiKVSR7bDbntRoit2xbK9vscc7Uf/N9dmRGfRYqWQrzuYG+5tsP88WkKcLtkZt5yOU65fsb/z86h2U29+pv3lawnun3RfZ2vPmaBLl8owtYO8N2d3WydUuyg1Owjuwk+zucTED3qMVe67VLLufm4/Y+71cYs815ewziJ9UJIWyVCSFslQkhbJUJIWyVCSFslQkhbJUJIWyVCSFKspFNhzL+vVfMJ1SSu0bj1CuGrDzlMPZVm2m8/4t9jNPHmW5G7dRrrXGRkNXh+wk4jOT91CuW3ZQ7teX/w3l/jJ9sTaT99io7cWz91GuX7EBH3W7v4hyrYINDJsP2fMtJurfnymllEb1P3f/RXYSc+IOG/Dle/AL35vsTGRVOH6T9AmwVCSFslQkhbJUJIWyVCSFslQkhbJUJIWyVCSFslQkhSoy+CXjVYstIMeL7NRdo8vWfhPX6he61VL9ycmUUsr22EqyungW5bbPsb/J8cYByr21u4ZyJ9o7KLc8yXJbL9UvjafusQX0rx37Fsqtj9ga+YnWJsolOGz9p6ufQbkT3Rsolw3Y0nzwbP1aduL6Y/RYCX5ROj2fmo1hbsDWyH5SkRTKUpEUylKRFMpSkRTKUpEUylKRFMpSkRTKUpEUylKRFKpIdE23sY1yjf40yh2eYjdF27fBYhF+sTVdIuaPd1Fu5vYsyl0dsi9yPzfJ7vt+tHcM5fbAfd+UUto+X/9/y/wHbBV8rvkQ5d7pn0G5jSG7ofz0xF2Uy9jbPQ3OLaNcsc1W2s3N/dpMOQe/tH6XvRa9Z9lN5qnL/45yCS7N/aQiKZSlIimUpSIplKUiKZSlIimUpSIplKUiKZSlIimUpSIpVEGD1Um2zqPa6+yb66uJ+lVo2WG3YqlspoNys+/eQ7n5vH5NmVJKeWLL4NcXP0C57/Quotwvf+lfazNXXngKPdZzLXaz9c099jduZuyG8kqxhXLtrYz93AdsVZ3g7ebBsfqlebHH/nZ0eTt1jT2H6tJ5lPNGraRPhKUiKZSlIimUpSIplKUiKZSlIimUpSIplKUiKZSlIilUkY3YYjENWa6cZHdR8122Ms3A/dm8x7pxdJTdO61ytrpMA7aAnMsPUW6x6KHcsy225N0r2yjXG9evW3/nqW+ix3qzP49y44q9Zr0xew6dDK49ByiWUsHuGdP7yM2t+ruy2Qge0F1nt4zT8hKKDafZKrh1Zw/l/KQiKZSlIimUpSIplKUiKZSlIimUpSIplKUiKZSlIimUpSIpVLHz4nEUnHv3AcrlcGU6PsLWrY1HO7WZcprdO21ssxVvasCuLdiJ37f6Z1BuptFHub/bfhnl9ku2bv701K3azOao/sZqSim93LmJcl/rv4Byd/fZQvdnZq6iXGeTLWCzPpzewkVtlte/p+i/iWqr/t9ESikV01Mo14LPYbTEfj8/qUgKZalICmWpSAplqUgKZalICmWpSAplqUgKZalICmWpSApVzL7P7l1WHbbOzLbYN80P1o6gXGe/ftk4mmWL2tZmF+VSxm7UVjvwuVZseXvz8CjKDSt2P3WuqL+LmlJK1/r1q+q5gq2R/3nvaZR7bgre2R3RG7VsyV302Xp0uMyWvMUGe0+VsxO1mfwG+5ukp59kuV12U7YCa9+UUioesefqJxVJoSwVSaEsFUmhLBVJoSwVSaEsFUmhLBVJoSwVSaEsFUmhivRgAwVHl9bYAw5HLNdlC8gMrAKbdAELV8Gp1WSPt8DutpbVdZSjS9mv/dcllHvpidso95WTV2ozf3rnF9FjdRrs9X9t8Ucod6fHlq3vzp5BufYW+/2ycYlyh6sLKNd6XL9IHj+5gh6rscXWzcNTbKFdbLLlbbbPbij7SUVSKEtFUihLRVIoS0VSKEtFUihLRVIoS0VSKEtFUihLRVKoorx4mgWvsnVmubrMHg+u+Mqjc7WZ7KD+jm1KfCXZP8G+3b5xwNaZVzaeQbnff+Iyyv1N77Mo9+rCNZR7a7/+5ulvLH8PPda1Q/b6f33jeZTb7bMbte2cLbS3z7NV9YkrWyhHZcNxbabY7oX+zMYOu42c4L+Lap79u/CTiqRQloqkUJaKpFCWiqRQloqkUJaKpFCWiqRQloqkUEW+DU/JTU+hXPXeByhXvvAsyuWHYNSUw3OSPXaGr+iyMd1wng2z3n/nHMp9eOwEyuVdNmpqJDZqWmnVD73+4fGL6LHKxF6Le736UWNKKT25yM6dnmk9QrmFj9hrS75QPaWUGntweHlwWJvpfYq9/pM3d1GuarDzpFWT5cazbDjoJxVJoSwVSaEsFUmhLBVJoSwVSaEsFUmhLBVJoSwVSaEsFUmhCnpicbiyiHKNOba8zR9to1w1M1mbGc/B9eM6W2cWj9hiMRuzL2g/9jY7w3fj55dQbvmphyj3/d2zKHdusn6N+vrif6DH+s7uBZT7zNItlJvM2WL1j6/9Enu8Ljs72diAq9XJDstN1K+vJ+6xdftgif0bK/boc+2i3HiqiXJ+UpEUylKRFMpSkRTKUpEUylKRFMpSkRTKUpEUylKRFMpSkRSqKGfrF6sp8Vuc+Q5bBQ5Xj7Kf262/7UkyKfE7u4OVBZRrbh2g3OK32Zfb/9afvIVyr0yxL17/bJt9yfijsqrN7JfsLu6vnthEufcGbMl9pXsJ5R532Ws7Db4oPaWURsfYDd1Gt49yKau/3ZvvsBvKnbtsGV4eZyv41GJL2eZDtrz1k4qkUJaKpFCWiqRQloqkUJaKpFCWiqRQloqkUJaKpFCWiqRQRSrZsjHvseUgvWVbbLH1IFkiphFbSZYL7KZs8zFbBSewRE0ppTRmv9/P/fXvodxwmv3c1i77P2PiQf3jHSyB1yEl/N9U0WO53jNsyX38m2zxm139AOXKT51jj9djq+pquv6OMsmklFI1WX/vNqWUsht3WW5uFuUGZ9gNZT+pSAplqUgKZalICmWpSAplqUgKZalICmWpSAplqUgKZalICvXfztVUh5vCuB8AAAAASUVORK5CYII=\" y=\"-27.871391\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_3\"/>\r\n   <g id=\"matplotlib.axis_4\"/>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 338.823529 304.871391 \r\nL 338.823529 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 615.176471 304.871391 \r\nL 615.176471 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 338.823529 304.871391 \r\nL 615.176471 304.871391 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 338.823529 28.51845 \r\nL 615.176471 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"text_2\">\r\n    <!-- Noisy Image -->\r\n    <defs>\r\n     <path d=\"M 9.8125 72.90625 \r\nL 23.09375 72.90625 \r\nL 55.421875 11.921875 \r\nL 55.421875 72.90625 \r\nL 64.984375 72.90625 \r\nL 64.984375 0 \r\nL 51.703125 0 \r\nL 19.390625 60.984375 \r\nL 19.390625 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-78\"/>\r\n     <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n     <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n    </defs>\r\n    <g transform=\"translate(414.499275 22.51845)scale(0.2016 -0.2016)\">\r\n     <use xlink:href=\"#DejaVuSans-78\"/>\r\n     <use x=\"74.804688\" xlink:href=\"#DejaVuSans-111\"/>\r\n     <use x=\"135.986328\" xlink:href=\"#DejaVuSans-105\"/>\r\n     <use x=\"163.769531\" xlink:href=\"#DejaVuSans-115\"/>\r\n     <use x=\"215.869141\" xlink:href=\"#DejaVuSans-121\"/>\r\n     <use x=\"275.048828\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"306.835938\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"336.328125\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"433.740234\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"495.019531\" xlink:href=\"#DejaVuSans-103\"/>\r\n     <use x=\"558.496094\" xlink:href=\"#DejaVuSans-101\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g id=\"patch_12\">\r\n    <path d=\"M 670.447059 304.871391 \r\nL 946.8 304.871391 \r\nL 946.8 28.51845 \r\nL 670.447059 28.51845 \r\nz\r\n\" style=\"fill:#f0f0f0;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pf2761faa48)\">\r\n    <image height=\"277\" id=\"image23bc3df5ab\" transform=\"scale(1 -1)translate(0 -277)\" width=\"277\" x=\"670.447059\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-27.871391\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_5\"/>\r\n   <g id=\"matplotlib.axis_6\"/>\r\n   <g id=\"patch_13\">\r\n    <path d=\"M 670.447059 304.871391 \r\nL 670.447059 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_14\">\r\n    <path d=\"M 946.8 304.871391 \r\nL 946.8 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_15\">\r\n    <path d=\"M 670.447059 304.871391 \r\nL 946.8 304.871391 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"patch_16\">\r\n    <path d=\"M 670.447059 28.51845 \r\nL 946.8 28.51845 \r\n\" style=\"fill:none;stroke:#f0f0f0;stroke-linecap:square;stroke-linejoin:miter;stroke-width:3;\"/>\r\n   </g>\r\n   <g id=\"text_3\">\r\n    <!-- Output Image -->\r\n    <defs>\r\n     <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n     <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n     <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n    </defs>\r\n    <g transform=\"translate(738.835279 22.51845)scale(0.2016 -0.2016)\">\r\n     <use xlink:href=\"#DejaVuSans-79\"/>\r\n     <use x=\"78.710938\" xlink:href=\"#DejaVuSans-117\"/>\r\n     <use x=\"142.089844\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"181.298828\" xlink:href=\"#DejaVuSans-112\"/>\r\n     <use x=\"244.775391\" xlink:href=\"#DejaVuSans-117\"/>\r\n     <use x=\"308.154297\" xlink:href=\"#DejaVuSans-116\"/>\r\n     <use x=\"347.363281\" xlink:href=\"#DejaVuSans-32\"/>\r\n     <use x=\"379.150391\" xlink:href=\"#DejaVuSans-73\"/>\r\n     <use x=\"408.642578\" xlink:href=\"#DejaVuSans-109\"/>\r\n     <use x=\"506.054688\" xlink:href=\"#DejaVuSans-97\"/>\r\n     <use x=\"567.333984\" xlink:href=\"#DejaVuSans-103\"/>\r\n     <use x=\"630.810547\" xlink:href=\"#DejaVuSans-101\"/>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p80ab465e04\">\r\n   <rect height=\"276.352941\" width=\"276.352941\" x=\"7.2\" y=\"28.51845\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p9483f64152\">\r\n   <rect height=\"276.352941\" width=\"276.352941\" x=\"338.823529\" y=\"28.51845\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pf2761faa48\">\r\n   <rect height=\"276.352941\" width=\"276.352941\" x=\"670.447059\" y=\"28.51845\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}